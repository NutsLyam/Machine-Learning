{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Dataset.csv', sep=',')\n",
    "df = df.drop(df.columns[0],axis=1)\n",
    "X = df[df.columns[:53]]\n",
    "Y = df[['Target']]\n",
    "X = normalize(X,Y,X.shape[0])\n",
    "#X = norm(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40900, 1)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#X[X.columns[36:38]]\n",
    "\n",
    "\n",
    "max_values_ind = Y.copy().sort_values('Target',ascending=False).head(49).index\n",
    "Y = Y.drop(Y.index[max_values_ind])\n",
    "X = X.drop(X.index[max_values_ind])\n",
    "#Y.sort_values('Target',ascending=False).head(100)\n",
    "X = X.reset_index(drop=True)\n",
    "Y = Y.reset_index(drop=True)\n",
    "Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def normalize(X,Y,nrows):\n",
    "    BinaryFeatures = ['Post Promotion Status','published_weekday_0','published_weekday_1','published_weekday_2',\n",
    "                      'published_weekday_3', 'published_weekday_4','published_weekday_5','published_weekday_6',\n",
    "                     'base_weekday_0','base_weekday_1','base_weekday_2','base_weekday_3','base_weekday_4',\n",
    "                      'base_weekday_5','base_weekday_6']\n",
    "    BF = X[BinaryFeatures] \n",
    "    \n",
    "    DecimalFeatures = ['Page Popularity','Page Checkins','Page talking about',\n",
    "                       'extra_0','extra_1','extra_2','extra_3','extra_4','extra_5',\n",
    "                       'extra_6','extra_7','extra_8','extra_9','extra_10',\n",
    "                       'extra_11','extra_12','extra_13','extra_14','extra_15','extra_16',\n",
    "                       'extra_17','extra_18','extra_19','extra_20','extra_21','extra_22','extra_23','extra_24',\n",
    "                       'CC1','CC2','CC3','CC4','CC5','Base Time','Post Length','Post Share Count','H Local']\n",
    "    DF = X[DecimalFeatures]\n",
    "    E = DF.mean()\n",
    "    D = DF.std()\n",
    "    DF = (DF-E)/D\n",
    "    \n",
    "    # 'H Local' feature's modification\n",
    "    #HLocal = Y['Target']/X['H Local']#comments/an hour \n",
    "    #CategoryFeature =['Page Category']\n",
    "    #CF = X[CategoryFeature]\n",
    "    \n",
    "    frequency = X['Page Category'].value_counts(sort=False) #frequency of categories\n",
    "    CF = 1/frequency[X['Page Category']]\n",
    "    CF = CF.reset_index(drop=True)\n",
    "    \n",
    "    # x0 = [1,1,...1] fpr b koeficient\n",
    "    x1 = pd.DataFrame({'feature 1': np.ones(nrows)})\n",
    "\n",
    "    result = pd.concat([x1,DF,CF, BF], axis=1) #,X['H Local']\n",
    "    return result\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gradient(X,Y,W,lyambda, n, nfeat):\n",
    "    Ypred = np.dot(X,W)\n",
    "    #print(Y[:10], Ypred[:10])\n",
    "    dy = Y - Ypred\n",
    "    cost = np.sum(dy**2)/n\n",
    "    #print( \"cost\", cost)\n",
    "    gr = np.dot(X.T,dy)/n\n",
    "    Wnew = W + 2* lyambda * gr.reshape(nfeat,1)\n",
    "    return Wnew\n",
    "\n",
    "def foo_RMSE(Xt, Yt, W):\n",
    "    rmse = math.sqrt(np.sum(((Yt-np.dot(Xt,W))**2))/len(Yt))\n",
    "    return rmse\n",
    "\n",
    "def foo_R2(X,Y,W):\n",
    "    Ey = Y.mean()\n",
    "    r2 = 1 - np.sum((np.dot(X,W)-Y)**2)/np.sum((Y - Ey)**2)\n",
    "    return r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nfolds = 5\n",
    "indexes = np.arange(X.shape[0]//nfolds * nfolds)\n",
    "indexes = indexes.reshape(X.shape[0]//nfolds,5)\n",
    "li =[] \n",
    "for i in range(nfolds):\n",
    "    li.append(indexes[:,i].tolist())\n",
    "Xfold =[]\n",
    "Yfold =[]\n",
    "for ind in li:\n",
    "    Xfold.append(X.loc[ind])\n",
    "    Yfold.append(Y.loc[ind])\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CHUNK #  1\n",
      "R2 for train:  0.41400440264 \n",
      "\n",
      "RMSE for train:  18.77310533355504 \n",
      "\n",
      "R2 for test:  0.345862524114 \n",
      "\n",
      "RMSE for test:  20.037095264073113 \n",
      "\n",
      "CHUNK #  2\n",
      "R2 for train:  0.365005787421 \n",
      "\n",
      "RMSE for train:  19.741726508912002 \n",
      "\n",
      "R2 for test:  0.398070902212 \n",
      "\n",
      "RMSE for test:  18.259225682487035 \n",
      "\n",
      "CHUNK #  3\n",
      "R2 for train:  0.42237829859 \n",
      "\n",
      "RMSE for train:  17.886750050819256 \n",
      "\n",
      "R2 for test:  0.397786436894 \n",
      "\n",
      "RMSE for test:  20.890970307927788 \n",
      "\n",
      "CHUNK #  4\n",
      "R2 for train:  0.426365847146 \n",
      "\n",
      "RMSE for train:  20.389230975584578 \n",
      "\n",
      "R2 for test:  0.419270240452 \n",
      "\n",
      "RMSE for test:  20.214093537826937 \n",
      "\n",
      "CHUNK #  5\n",
      "R2 for train:  0.432217070214 \n",
      "\n",
      "RMSE for train:  19.987496269799667 \n",
      "\n",
      "R2 for test:  0.378169952695 \n",
      "\n",
      "RMSE for test:  19.33858938666766 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "nsteps = 500\n",
    "e = 10e-5\n",
    "\n",
    "lyambda = 0.05\n",
    "table = pd.DataFrame({})\n",
    "nfeatures = X.shape[1]\n",
    "chunk = 0\n",
    "for i in range(nfolds):\n",
    "    \n",
    "    Xtrain = Xfold[i]\n",
    "    Xtest = Xfold[(i+1)%5]\n",
    "    Ytrain = Yfold[i]\n",
    "    Ytest = Yfold[(i+1)%5]\n",
    "    \n",
    "    nrows = Xtrain.shape[0]\n",
    "    chunk+=1\n",
    "    k = 0\n",
    "    W = np.ones(nfeatures).reshape(nfeatures,1)\n",
    "    while True:\n",
    "        k+=1\n",
    "        Wnew = gradient(Xtrain,Ytrain,W,lyambda/math.sqrt(k), nrows, nfeatures)\n",
    "        estimation = np.max(abs(W - Wnew))\n",
    "    \n",
    "        if (estimation < e)or(k>nsteps):\n",
    "            break\n",
    "        W = Wnew\n",
    "        \n",
    "    print(\"CHUNK # \", chunk)    \n",
    "    R2train = foo_R2(Xtrain,Ytrain,W)\n",
    "    print (\"R2 for train: \",R2train[0] , \"\\n\")\n",
    "\n",
    "    RMSEtrain = foo_RMSE(Xtrain,Ytrain,W)\n",
    "    print (\"RMSE for train: \",RMSEtrain , \"\\n\") \n",
    " \n",
    "    \n",
    "    #test\n",
    "    R2test = foo_R2(Xtest,Ytest,W)\n",
    "    print (\"R2 for test: \",R2test[0] , \"\\n\")\n",
    "\n",
    "    RMSEtest = foo_RMSE(Xtest,Ytest,W)\n",
    "    print (\"RMSE for test: \",RMSEtest , \"\\n\")\n",
    "   \n",
    "    \n",
    "    a = [R2train[0],RMSEtrain,R2test[0],RMSEtest]\n",
    "    \n",
    "    for feature in W.tolist():\n",
    "        a.append(feature[0])\n",
    "    col = pd.DataFrame({'chunk %d'%chunk: a })\n",
    "    table =  pd.concat([table, col],axis = 1)\n",
    "\n",
    "\n",
    "table.index=['R2_train', 'RMSE_train', 'R2_test', 'RMSE_test','b','Page Popularity','Page Checkins',\n",
    "             'Page talking about','extra_0','extra_1','extra_2','extra_3','extra_4','extra_5','extra_6',\n",
    "             'extra_7','extra_8','extra_9','extra_10','extra_11','extra_12','extra_13','extra_14','extra_15',\n",
    "             'extra_16','extra_17','extra_18','extra_19','extra_20','extra_21','extra_22','extra_23','extra_24',\n",
    "             'CC1','CC2','CC3','CC4','CC5','Base Time','Post Length','Post Share Count','H Local','Page Category', \n",
    "             'Post Promotion Status','published_weekday_0','published_weekday_1','published_weekday_2',\n",
    "             'published_weekday_3', 'published_weekday_4','published_weekday_5','published_weekday_6',\n",
    "             'base_weekday_0','base_weekday_1','base_weekday_2','base_weekday_3','base_weekday_4',\n",
    "             'base_weekday_5','base_weekday_6']\n",
    "table.index.name = 'Features'\n",
    "table =  pd.concat([table, pd.DataFrame({'E': table.mean(axis = 1) })],axis = 1)\n",
    "table =  pd.concat([table, pd.DataFrame({'STD': table.std(axis = 1) })],axis = 1)\n",
    "table.to_csv('table.csv')   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
